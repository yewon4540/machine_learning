{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part4_2 Randomforest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\user\\\\Documents\\\\ML\\\\wk2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 현재경로 확인\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>feat_1</th>\n",
       "      <th>feat_2</th>\n",
       "      <th>feat_3</th>\n",
       "      <th>feat_4</th>\n",
       "      <th>feat_5</th>\n",
       "      <th>feat_6</th>\n",
       "      <th>feat_7</th>\n",
       "      <th>feat_8</th>\n",
       "      <th>feat_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_85</th>\n",
       "      <th>feat_86</th>\n",
       "      <th>feat_87</th>\n",
       "      <th>feat_88</th>\n",
       "      <th>feat_89</th>\n",
       "      <th>feat_90</th>\n",
       "      <th>feat_91</th>\n",
       "      <th>feat_92</th>\n",
       "      <th>feat_93</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 95 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  feat_1  feat_2  feat_3  feat_4  feat_5  feat_6  feat_7  feat_8  feat_9  \\\n",
       "0   1       1       0       0       0       0       0       0       0       0   \n",
       "1   2       0       0       0       0       0       0       0       1       0   \n",
       "2   3       0       0       0       0       0       0       0       1       0   \n",
       "3   4       1       0       0       1       6       1       5       0       0   \n",
       "4   5       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   ...  feat_85  feat_86  feat_87  feat_88  feat_89  feat_90  feat_91  \\\n",
       "0  ...        1        0        0        0        0        0        0   \n",
       "1  ...        0        0        0        0        0        0        0   \n",
       "2  ...        0        0        0        0        0        0        0   \n",
       "3  ...        0        1        2        0        0        0        0   \n",
       "4  ...        1        0        0        0        0        1        0   \n",
       "\n",
       "   feat_92  feat_93   target  \n",
       "0        0        0  Class_1  \n",
       "1        0        0  Class_1  \n",
       "2        0        0  Class_1  \n",
       "3        0        0  Class_1  \n",
       "4        0        0  Class_1  \n",
       "\n",
       "[5 rows x 95 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"./otto_train.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nid : 고유 아이디\\nfeat_1 ~ feat_93 : 설명변수\\ntarget : 타겟변수 (1~9)\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "id : 고유 아이디\n",
    "feat_1 ~ feat_93 : 설명변수\n",
    "target : 타겟변수 (1~9)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nCar : 61878 nVar : 95\n"
     ]
    }
   ],
   "source": [
    "nCar = data.shape[0] # 데이터 개수\n",
    "nVar = data.shape[1] # 변수 개수\n",
    "print('nCar : %d' % nCar, 'nVar : %d' % nVar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 의미 없는 변수 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['id'], axis= 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 타겟 변수의 문자열을 숫자로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_dict = {}\n",
    "\n",
    "for nm in range(9):\n",
    "    mapping_dict[f'Class_{nm+1}'] = nm+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "after_mapping_target = data['target'].apply(lambda x : mapping_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1\n",
       "1        1\n",
       "2        1\n",
       "3        1\n",
       "4        1\n",
       "        ..\n",
       "61873    9\n",
       "61874    9\n",
       "61875    9\n",
       "61876    9\n",
       "61877    9\n",
       "Name: target, Length: 61878, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "after_mapping_target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 설명변수와 타겟변수를 분리, 학습데이터와 평가데이터 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49502, 93) (12376, 93) (49502,) (12376,)\n"
     ]
    }
   ],
   "source": [
    "feature_columns = list(data.columns.difference(['target']))\n",
    "X = data[feature_columns]\n",
    "y = after_mapping_target\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "print(train_X.shape, test_X.shape, train_y.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습 데이터를 랜덤포레스트 모형에 적합 후 평가 데이터로 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 60.02 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "random_forest_model1 = RandomForestClassifier(n_estimators=20, # 20번 추정\n",
    "                                                max_depth=5, #트리 최대 깊이 5 -> 너무 깊어지면  과대적합이 일어난다.(정확도가 100에 가까워짐) \n",
    "                                                            # -> train에는 좋아도 사용하기에는 부적합\n",
    "                                                random_state= 40) #시드값 고정\n",
    "model1 = random_forest_model1.fit(train_X, train_y) # 학습 진행\n",
    "predict1 = model1.predict(test_X) # 평가 데이터 예측\n",
    "print(\"Accuracy: %.2f\" % (accuracy_score(test_y, predict1) * 100), \"%\") # 정확도 계산 (test_y : 정답, predict : 모델이 추출한 답)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 트리를 많이 만들어보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 59.80 %\n"
     ]
    }
   ],
   "source": [
    "random_forest_model2 = RandomForestClassifier(n_estimators=300, # 300번 추정\n",
    "                                                max_depth=5, #트리 최대 깊이 5\n",
    "                                                random_state= 40) #시드값 고정\n",
    "model2 = random_forest_model2.fit(train_X, train_y) # 학습 진행\n",
    "predict2 = model2.predict(test_X) # 평가 데이터 예측\n",
    "print(\"Accuracy: %.2f\" % (accuracy_score(test_y, predict2) * 100), \"%\") # 정확도 계산\n",
    "\n",
    "# 큰 차이가 없다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 트리의 깊이 늘이기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 77.86 %\n"
     ]
    }
   ],
   "source": [
    "random_forest_model3 = RandomForestClassifier(n_estimators=300, # 300번 추정\n",
    "                                                max_depth=20, #트리 최대 깊이 20\n",
    "                                                random_state= 40) #시드값 고정\n",
    "model3 = random_forest_model3.fit(train_X, train_y) # 학습 진행\n",
    "predict3 = model3.predict(test_X) # 평가 데이터 예측\n",
    "print(\"Accuracy: %.2f\" % (accuracy_score(test_y, predict3) * 100), \"%\") # 정확도 계산\n",
    "\n",
    "# accuracy_score가 80정도 나오면 쓸만하다(경험학적인 관점)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 트리의 깊이 최대로 늘려보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 80.98 %\n"
     ]
    }
   ],
   "source": [
    "random_forest_model4 = RandomForestClassifier(n_estimators=300, # 300번 추정\n",
    "                                                max_depth=100, #트리 최대 깊이 100\n",
    "                                                random_state= 40) #시드값 고정\n",
    "model4 = random_forest_model4.fit(train_X, train_y) # 학습 진행\n",
    "predict4 = model4.predict(test_X) # 평가 데이터 예측\n",
    "print(\"Accuracy: %.2f\" % (accuracy_score(test_y, predict4) * 100), \"%\") # 정확도 계산"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part4_4 Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import pandas as pd\n",
    "# import numpy as pd\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\user\\\\Documents\\\\ML\\\\wk2'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>feat_1</th>\n",
       "      <th>feat_2</th>\n",
       "      <th>feat_3</th>\n",
       "      <th>feat_4</th>\n",
       "      <th>feat_5</th>\n",
       "      <th>feat_6</th>\n",
       "      <th>feat_7</th>\n",
       "      <th>feat_8</th>\n",
       "      <th>feat_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_85</th>\n",
       "      <th>feat_86</th>\n",
       "      <th>feat_87</th>\n",
       "      <th>feat_88</th>\n",
       "      <th>feat_89</th>\n",
       "      <th>feat_90</th>\n",
       "      <th>feat_91</th>\n",
       "      <th>feat_92</th>\n",
       "      <th>feat_93</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 95 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  feat_1  feat_2  feat_3  feat_4  feat_5  feat_6  feat_7  feat_8  feat_9  \\\n",
       "0   1       1       0       0       0       0       0       0       0       0   \n",
       "1   2       0       0       0       0       0       0       0       1       0   \n",
       "2   3       0       0       0       0       0       0       0       1       0   \n",
       "3   4       1       0       0       1       6       1       5       0       0   \n",
       "4   5       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   ...  feat_85  feat_86  feat_87  feat_88  feat_89  feat_90  feat_91  \\\n",
       "0  ...        1        0        0        0        0        0        0   \n",
       "1  ...        0        0        0        0        0        0        0   \n",
       "2  ...        0        0        0        0        0        0        0   \n",
       "3  ...        0        1        2        0        0        0        0   \n",
       "4  ...        1        0        0        0        0        1        0   \n",
       "\n",
       "   feat_92  feat_93   target  \n",
       "0        0        0  Class_1  \n",
       "1        0        0  Class_1  \n",
       "2        0        0  Class_1  \n",
       "3        0        0  Class_1  \n",
       "4        0        0  Class_1  \n",
       "\n",
       "[5 rows x 95 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./otto_train.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cCar: 61878 cVar: 94\n"
     ]
    }
   ],
   "source": [
    "cCar = data.shape[0]\n",
    "cVar = data.shape[1]\n",
    "print('cCar: %d' % cCar, 'cVar: %d' % cVar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 의미가 없다고 판단되는 변수 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['id'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 타겟 변수의 문자열을 숫자로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_dict = {}\n",
    "\n",
    "for nm in range(9):\n",
    "    mapping_dict[f'Class_{nm+1}'] = nm+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 타겟 변수의 문자열을 숫자로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "after_mapping_target = data.target.apply(lambda x : mapping_dict[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 설명변수와 타겟변수를 분리, 학습데이터와 평가데이터 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49502, 93) (12376, 93) (49502,) (12376,)\n"
     ]
    }
   ],
   "source": [
    "feature_columns = list(data.columns.difference(['target']))\n",
    "X = data[feature_columns]\n",
    "y = after_mapping_target\n",
    "train_x, test_x, train_y, test_y = train_test_split(X, y, test_size=0.2, random_state=40)\n",
    "print(train_x.shape, test_x.shape, train_y.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. XGBoost\n",
    "\n",
    "꼭 이 방법을 사용하지 않아도 괜찮다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:27:28] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "Accuracy : 75.57 %\n",
      "Time : 1.88 seconds\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "import time\n",
    "start = time.time() # 시작 시간 지정\n",
    "xgb_dtrain = xgb.DMatrix(data = train_x, label = train_y) # 학습 데이터를 XGBoost 모델에 맞게 변환\n",
    "xgb_dtest = xgb.DMatrix(data = test_x) # 평가 데이터를 XGBoost 모델에 맞게 변환\n",
    "xgb_param = {'max_depth' : 10,\n",
    "            'learning_rate' : 0.01, # Stepsize\n",
    "            'n_estimators' : 100, # Number of trees, 트리 생성 개수\n",
    "            'objective' : 'multi:softmax', # 목적 함수\n",
    "            'num_class' : len(set(train_y)) +1 # 파라미터 추가, Label must be in (0, num_class) -> num_class보다 1 커야함.\n",
    "            }\n",
    "xgb_model = xgb.train(params = xgb_param, dtrain= xgb_dtrain)\n",
    "xgb_model_predict = xgb_model.predict(xgb_dtest)\n",
    "print(\"Accuracy : %.2f\" % (accuracy_score(test_y, xgb_model_predict) * 100), \"%\") # 정확도 % 계산\n",
    "print(\"Time : %.2f\" % (time.time() - start), \"seconds\") # 코드 실행 시간 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9., 6., 6., ..., 8., 8., 9.], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in c:\\programdata\\anaconda3\\lib\\site-packages (3.3.4)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from lightgbm) (1.21.5)\n",
      "Requirement already satisfied: scikit-learn!=0.22.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from lightgbm) (1.0.2)\n",
      "Requirement already satisfied: scipy in c:\\programdata\\anaconda3\\lib\\site-packages (from lightgbm) (1.9.1)\n",
      "Requirement already satisfied: wheel in c:\\programdata\\anaconda3\\lib\\site-packages (from lightgbm) (0.37.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn!=0.22.0->lightgbm) (2.2.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn!=0.22.0->lightgbm) (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005475 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3140\n",
      "[LightGBM] [Info] Number of data points in the train set: 49502, number of used features: 93\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -3.444588\n",
      "[LightGBM] [Info] Start training from score -1.343082\n",
      "[LightGBM] [Info] Start training from score -2.041661\n",
      "[LightGBM] [Info] Start training from score -3.145422\n",
      "[LightGBM] [Info] Start training from score -3.110832\n",
      "[LightGBM] [Info] Start training from score -1.482623\n",
      "[LightGBM] [Info] Start training from score -3.073461\n",
      "[LightGBM] [Info] Start training from score -1.990842\n",
      "[LightGBM] [Info] Start training from score -2.529057\n",
      "Accuracy : 80.91 %\n",
      "Time : 1.57 seconds\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "start = time.time()\n",
    "lgb_dtrain = lgb.Dataset(data = train_x, label = train_y) # 학습데이터를 LightGBM 모델에 맞게 변환\n",
    "lgb_param = {'max_depth' : 10, # 트리 깊이\n",
    "            'learning_rate' : 0.1, # Step size\n",
    "            'n_estimators' : 100, # Number of trees, 트리생성개수\n",
    "            'objective' : 'multiclass', # 목적 함수\n",
    "            'num_class' : len(set(train_y)) +1 # 파라미터 추가, Label must be in (0, num_class) -> num_class보다 1 커야함.\n",
    "            }\n",
    "lgb_model = lgb.train(params= lgb_param, train_set= lgb_dtrain)\n",
    "lgb_model_predict = np.argmax(lgb_model.predict(test_x), axis = 1) # 평가 데이터 예측, Softmax의 결과값 중 가장 큰 값의 Label로 예측\n",
    "print(\"Accuracy : %.2f\" % (accuracy_score(test_y, lgb_model_predict) * 100), \"%\") # 정확도 % 계산\n",
    "print(\"Time : %.2f\" % (time.time() - start), \"seconds\") # 코드 실행 시간 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 6, 6, ..., 8, 8, 9], dtype=int64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_model_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: catboost in c:\\programdata\\anaconda3\\lib\\site-packages (1.1.1)\n",
      "Requirement already satisfied: six in c:\\programdata\\anaconda3\\lib\\site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: scipy in c:\\programdata\\anaconda3\\lib\\site-packages (from catboost) (1.9.1)\n",
      "Requirement already satisfied: matplotlib in c:\\programdata\\anaconda3\\lib\\site-packages (from catboost) (3.5.2)\n",
      "Requirement already satisfied: numpy>=1.16.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from catboost) (1.21.5)\n",
      "Requirement already satisfied: plotly in c:\\programdata\\anaconda3\\lib\\site-packages (from catboost) (5.11.0)\n",
      "Requirement already satisfied: pandas>=0.24.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from catboost) (1.4.4)\n",
      "Requirement already satisfied: graphviz in c:\\programdata\\anaconda3\\lib\\site-packages (from catboost) (0.20.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas>=0.24.0->catboost) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas>=0.24.0->catboost) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (1.4.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (9.2.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (4.25.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (3.0.9)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (0.11.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (21.3)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from plotly->catboost) (8.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.5955921\ttotal: 423ms\tremaining: 41.9s\n",
      "1:\tlearn: 0.6352673\ttotal: 677ms\tremaining: 33.2s\n",
      "2:\tlearn: 0.6531049\ttotal: 917ms\tremaining: 29.6s\n",
      "3:\tlearn: 0.6581956\ttotal: 1.17s\tremaining: 28.1s\n",
      "4:\tlearn: 0.6660741\ttotal: 1.44s\tremaining: 27.3s\n",
      "5:\tlearn: 0.6715890\ttotal: 1.69s\tremaining: 26.5s\n",
      "6:\tlearn: 0.6766191\ttotal: 1.95s\tremaining: 25.9s\n",
      "7:\tlearn: 0.6813058\ttotal: 2.19s\tremaining: 25.2s\n",
      "8:\tlearn: 0.6868409\ttotal: 2.46s\tremaining: 24.9s\n",
      "9:\tlearn: 0.6916488\ttotal: 2.74s\tremaining: 24.7s\n",
      "10:\tlearn: 0.6960729\ttotal: 3.01s\tremaining: 24.4s\n",
      "11:\tlearn: 0.6991435\ttotal: 3.28s\tremaining: 24s\n",
      "12:\tlearn: 0.7013050\ttotal: 3.55s\tremaining: 23.8s\n",
      "13:\tlearn: 0.7032645\ttotal: 3.8s\tremaining: 23.4s\n",
      "14:\tlearn: 0.7063351\ttotal: 4.06s\tremaining: 23s\n",
      "15:\tlearn: 0.7092643\ttotal: 4.32s\tremaining: 22.7s\n",
      "16:\tlearn: 0.7114662\ttotal: 4.57s\tremaining: 22.3s\n",
      "17:\tlearn: 0.7135671\ttotal: 4.8s\tremaining: 21.9s\n",
      "18:\tlearn: 0.7169003\ttotal: 5.05s\tremaining: 21.5s\n",
      "19:\tlearn: 0.7200719\ttotal: 5.3s\tremaining: 21.2s\n",
      "20:\tlearn: 0.7229203\ttotal: 5.54s\tremaining: 20.8s\n",
      "21:\tlearn: 0.7244556\ttotal: 5.77s\tremaining: 20.5s\n",
      "22:\tlearn: 0.7274656\ttotal: 6s\tremaining: 20.1s\n",
      "23:\tlearn: 0.7315260\ttotal: 6.23s\tremaining: 19.7s\n",
      "24:\tlearn: 0.7332431\ttotal: 6.46s\tremaining: 19.4s\n",
      "25:\tlearn: 0.7352026\ttotal: 6.7s\tremaining: 19.1s\n",
      "26:\tlearn: 0.7372227\ttotal: 6.94s\tremaining: 18.8s\n",
      "27:\tlearn: 0.7390610\ttotal: 7.15s\tremaining: 18.4s\n",
      "28:\tlearn: 0.7398691\ttotal: 7.36s\tremaining: 18s\n",
      "29:\tlearn: 0.7417680\ttotal: 7.56s\tremaining: 17.6s\n",
      "30:\tlearn: 0.7433841\ttotal: 7.74s\tremaining: 17.2s\n",
      "31:\tlearn: 0.7445356\ttotal: 7.92s\tremaining: 16.8s\n",
      "32:\tlearn: 0.7458487\ttotal: 8.1s\tremaining: 16.4s\n",
      "33:\tlearn: 0.7475052\ttotal: 8.27s\tremaining: 16.1s\n",
      "34:\tlearn: 0.7489394\ttotal: 8.46s\tremaining: 15.7s\n",
      "35:\tlearn: 0.7503131\ttotal: 8.63s\tremaining: 15.3s\n",
      "36:\tlearn: 0.7515656\ttotal: 8.81s\tremaining: 15s\n",
      "37:\tlearn: 0.7524544\ttotal: 9s\tremaining: 14.7s\n",
      "38:\tlearn: 0.7535251\ttotal: 9.18s\tremaining: 14.4s\n",
      "39:\tlearn: 0.7549190\ttotal: 9.36s\tremaining: 14s\n",
      "40:\tlearn: 0.7565351\ttotal: 9.54s\tremaining: 13.7s\n",
      "41:\tlearn: 0.7583128\ttotal: 9.72s\tremaining: 13.4s\n",
      "42:\tlearn: 0.7589592\ttotal: 9.91s\tremaining: 13.1s\n",
      "43:\tlearn: 0.7603329\ttotal: 10.1s\tremaining: 12.8s\n",
      "44:\tlearn: 0.7606763\ttotal: 10.3s\tremaining: 12.5s\n",
      "45:\tlearn: 0.7616662\ttotal: 10.5s\tremaining: 12.3s\n",
      "46:\tlearn: 0.7628783\ttotal: 10.6s\tremaining: 12s\n",
      "47:\tlearn: 0.7641105\ttotal: 10.8s\tremaining: 11.7s\n",
      "48:\tlearn: 0.7653226\ttotal: 11s\tremaining: 11.5s\n",
      "49:\tlearn: 0.7662519\ttotal: 11.2s\tremaining: 11.2s\n",
      "50:\tlearn: 0.7678882\ttotal: 11.4s\tremaining: 10.9s\n",
      "51:\tlearn: 0.7685952\ttotal: 11.6s\tremaining: 10.7s\n",
      "52:\tlearn: 0.7691608\ttotal: 11.7s\tremaining: 10.4s\n",
      "53:\tlearn: 0.7699285\ttotal: 11.9s\tremaining: 10.2s\n",
      "54:\tlearn: 0.7708173\ttotal: 12.1s\tremaining: 9.91s\n",
      "55:\tlearn: 0.7725344\ttotal: 12.3s\tremaining: 9.67s\n",
      "56:\tlearn: 0.7735647\ttotal: 12.5s\tremaining: 9.42s\n",
      "57:\tlearn: 0.7751808\ttotal: 12.7s\tremaining: 9.17s\n",
      "58:\tlearn: 0.7761303\ttotal: 12.9s\tremaining: 8.93s\n",
      "59:\tlearn: 0.7779282\ttotal: 13s\tremaining: 8.69s\n",
      "60:\tlearn: 0.7786150\ttotal: 13.2s\tremaining: 8.45s\n",
      "61:\tlearn: 0.7792412\ttotal: 13.4s\tremaining: 8.22s\n",
      "62:\tlearn: 0.7801301\ttotal: 13.6s\tremaining: 7.98s\n",
      "63:\tlearn: 0.7813220\ttotal: 13.8s\tremaining: 7.75s\n",
      "64:\tlearn: 0.7819482\ttotal: 13.9s\tremaining: 7.51s\n",
      "65:\tlearn: 0.7834835\ttotal: 14.1s\tremaining: 7.28s\n",
      "66:\tlearn: 0.7837865\ttotal: 14.3s\tremaining: 7.05s\n",
      "67:\tlearn: 0.7846754\ttotal: 14.5s\tremaining: 6.82s\n",
      "68:\tlearn: 0.7848370\ttotal: 14.7s\tremaining: 6.6s\n",
      "69:\tlearn: 0.7861905\ttotal: 14.9s\tremaining: 6.37s\n",
      "70:\tlearn: 0.7867965\ttotal: 15.1s\tremaining: 6.15s\n",
      "71:\tlearn: 0.7871803\ttotal: 15.2s\tremaining: 5.93s\n",
      "72:\tlearn: 0.7879076\ttotal: 15.4s\tremaining: 5.7s\n",
      "73:\tlearn: 0.7884934\ttotal: 15.6s\tremaining: 5.48s\n",
      "74:\tlearn: 0.7889378\ttotal: 15.8s\tremaining: 5.26s\n",
      "75:\tlearn: 0.7890186\ttotal: 16s\tremaining: 5.04s\n",
      "76:\tlearn: 0.7895237\ttotal: 16.1s\tremaining: 4.82s\n",
      "77:\tlearn: 0.7896651\ttotal: 16.3s\tremaining: 4.61s\n",
      "78:\tlearn: 0.7904731\ttotal: 16.5s\tremaining: 4.4s\n",
      "79:\tlearn: 0.7916044\ttotal: 16.7s\tremaining: 4.18s\n",
      "80:\tlearn: 0.7918064\ttotal: 16.9s\tremaining: 3.97s\n",
      "81:\tlearn: 0.7920488\ttotal: 17.1s\tremaining: 3.76s\n",
      "82:\tlearn: 0.7925336\ttotal: 17.3s\tremaining: 3.55s\n",
      "83:\tlearn: 0.7929781\ttotal: 17.5s\tremaining: 3.34s\n",
      "84:\tlearn: 0.7934225\ttotal: 17.7s\tremaining: 3.13s\n",
      "85:\tlearn: 0.7937255\ttotal: 17.9s\tremaining: 2.91s\n",
      "86:\tlearn: 0.7944527\ttotal: 18.1s\tremaining: 2.7s\n",
      "87:\tlearn: 0.7947962\ttotal: 18.3s\tremaining: 2.49s\n",
      "88:\tlearn: 0.7957456\ttotal: 18.5s\tremaining: 2.28s\n",
      "89:\tlearn: 0.7960082\ttotal: 18.7s\tremaining: 2.07s\n",
      "90:\tlearn: 0.7967961\ttotal: 18.9s\tremaining: 1.86s\n",
      "91:\tlearn: 0.7969375\ttotal: 19s\tremaining: 1.66s\n",
      "92:\tlearn: 0.7981496\ttotal: 19.2s\tremaining: 1.45s\n",
      "93:\tlearn: 0.7981496\ttotal: 19.4s\tremaining: 1.24s\n",
      "94:\tlearn: 0.7993818\ttotal: 19.6s\tremaining: 1.03s\n",
      "95:\tlearn: 0.8002303\ttotal: 19.8s\tremaining: 827ms\n",
      "96:\tlearn: 0.8005939\ttotal: 20s\tremaining: 620ms\n",
      "97:\tlearn: 0.8014424\ttotal: 20.2s\tremaining: 413ms\n",
      "98:\tlearn: 0.8024120\ttotal: 20.4s\tremaining: 207ms\n",
      "99:\tlearn: 0.8032201\ttotal: 20.6s\tremaining: 0us\n",
      "Accuracy : 3.87 %\n",
      "Time : 20.78 seconds\n"
     ]
    }
   ],
   "source": [
    "import catboost as cb\n",
    "start = time.time()\n",
    "cb_dtrain = cb.Pool(data = train_x, label = train_y) # 학습데이터를 LightGBM 모델에 맞게 변환\n",
    "cb_param = {'max_depth' : 10, # 트리 깊이\n",
    "            'learning_rate' : 0.1, # Step size\n",
    "            'n_estimators' : 100, # Number of trees, 트리생성개수\n",
    "            'eval_metric' : 'Accuracy', # 평가 척도\n",
    "            'loss_function' : 'MultiClass' # 손실 함수, 목적 함수\n",
    "            }\n",
    "cb_model = cb.train(pool= cb_dtrain, params= cb_param)\n",
    "cb_model_predict = np.argmax(cb_model.predict(test_x), axis = 1) # 평가 데이터 예측, Softmax의 결과값 중 가장 큰 값의 Label로 예측\n",
    "print(\"Accuracy : %.2f\" % (accuracy_score(test_y, cb_model_predict) * 100), \"%\") # 정확도 % 계산\n",
    "print(\"Time : %.2f\" % (time.time() - start), \"seconds\") # 코드 실행 시간 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.21253034,  0.65684363,  0.07120576, ..., -0.6950527 ,\n",
       "         0.52780085,  2.47129728],\n",
       "       [-0.26592681, -0.9386558 , -1.55880405, ..., -0.34333762,\n",
       "         0.44284098, -0.57560756],\n",
       "       [ 1.06973695, -1.95046866, -2.31159984, ..., -0.37514737,\n",
       "         2.35229294,  0.93325542],\n",
       "       ...,\n",
       "       [ 1.09505722, -0.89480159, -0.84397374, ..., -1.1409345 ,\n",
       "         3.64063393,  2.49051575],\n",
       "       [ 1.02570074, -1.7024878 , -2.09985945, ...,  0.1288898 ,\n",
       "         6.92558706,  0.47816423],\n",
       "       [ 1.94838412, -1.00317417, -1.60780683, ..., -0.3745579 ,\n",
       "        -0.0301398 ,  3.4741448 ]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cb_model.predict(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 앙상블"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>...</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7129300520</td>\n",
       "      <td>20141013T000000</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1180.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6414100192</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>538000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570</td>\n",
       "      <td>7242</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>2170.0</td>\n",
       "      <td>400</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>1690</td>\n",
       "      <td>7639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5631500400</td>\n",
       "      <td>20150225T000000</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>770.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1933</td>\n",
       "      <td>0</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2487200875</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>604000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1050.0</td>\n",
       "      <td>910</td>\n",
       "      <td>1965</td>\n",
       "      <td>0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>-122.393</td>\n",
       "      <td>1360</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1954400510</td>\n",
       "      <td>20150218T000000</td>\n",
       "      <td>510000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1680.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id             date     price  bedrooms  bathrooms  sqft_living  \\\n",
       "0  7129300520  20141013T000000  221900.0         3       1.00         1180   \n",
       "1  6414100192  20141209T000000  538000.0         3       2.25         2570   \n",
       "2  5631500400  20150225T000000  180000.0         2       1.00          770   \n",
       "3  2487200875  20141209T000000  604000.0         4       3.00         1960   \n",
       "4  1954400510  20150218T000000  510000.0         3       2.00         1680   \n",
       "\n",
       "   sqft_lot  floors  waterfront  view  ...  grade  sqft_above  sqft_basement  \\\n",
       "0      5650     1.0           0     0  ...      7      1180.0              0   \n",
       "1      7242     2.0           0     0  ...      7      2170.0            400   \n",
       "2     10000     1.0           0     0  ...      6       770.0              0   \n",
       "3      5000     1.0           0     0  ...      7      1050.0            910   \n",
       "4      8080     1.0           0     0  ...      8      1680.0              0   \n",
       "\n",
       "   yr_built  yr_renovated  zipcode      lat     long  sqft_living15  \\\n",
       "0      1955             0    98178  47.5112 -122.257           1340   \n",
       "1      1951          1991    98125  47.7210 -122.319           1690   \n",
       "2      1933             0    98028  47.7379 -122.233           2720   \n",
       "3      1965             0    98136  47.5208 -122.393           1360   \n",
       "4      1987             0    98074  47.6168 -122.045           1800   \n",
       "\n",
       "   sqft_lot15  \n",
       "0        5650  \n",
       "1        7639  \n",
       "2        8062  \n",
       "3        5000  \n",
       "4        7503  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"./kc_house_data.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['id', 'date', 'zipcode', 'lat','long'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>condition</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>221900.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1180.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>538000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570</td>\n",
       "      <td>7242</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2170.0</td>\n",
       "      <td>400</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991</td>\n",
       "      <td>1690</td>\n",
       "      <td>7639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>180000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>770.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1933</td>\n",
       "      <td>0</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>604000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1050.0</td>\n",
       "      <td>910</td>\n",
       "      <td>1965</td>\n",
       "      <td>0</td>\n",
       "      <td>1360</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>510000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1680.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      price  bedrooms  bathrooms  sqft_living  sqft_lot  floors  waterfront  \\\n",
       "0  221900.0         3       1.00         1180      5650     1.0           0   \n",
       "1  538000.0         3       2.25         2570      7242     2.0           0   \n",
       "2  180000.0         2       1.00          770     10000     1.0           0   \n",
       "3  604000.0         4       3.00         1960      5000     1.0           0   \n",
       "4  510000.0         3       2.00         1680      8080     1.0           0   \n",
       "\n",
       "   view  condition  grade  sqft_above  sqft_basement  yr_built  yr_renovated  \\\n",
       "0     0          3      7      1180.0              0      1955             0   \n",
       "1     0          3      7      2170.0            400      1951          1991   \n",
       "2     0          3      6       770.0              0      1933             0   \n",
       "3     0          5      7      1050.0            910      1965             0   \n",
       "4     0          3      8      1680.0              0      1987             0   \n",
       "\n",
       "   sqft_living15  sqft_lot15  \n",
       "0           1340        5650  \n",
       "1           1690        7639  \n",
       "2           2720        8062  \n",
       "3           1360        5000  \n",
       "4           1800        7503  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15129, 15) (6484, 15) (15129,) (6484,)\n"
     ]
    }
   ],
   "source": [
    "feature_columns = list(data.columns.difference(['price']))\n",
    "X = data[feature_columns]\n",
    "y = data['price']\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(X, y, test_size=0.3, random_state= 40)\n",
    "print(train_x.shape, test_x.shape, train_y.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: learning_reat\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Unknown parameter: learning_reat\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000769 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1745\n",
      "[LightGBM] [Info] Number of data points in the train set: 15129, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 539524.963712\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    }
   ],
   "source": [
    "# import lightgbm as lgb\n",
    "start = time.time()\n",
    "lgb_dtrain = lgb.Dataset(data = train_x, label = train_y)\n",
    "lgb_param = {'max_depth' : 10,\n",
    "            'learning_reat': 0.01,\n",
    "            'n_estimators' : 500,\n",
    "            'objective' : 'regression'}\n",
    "lgb_model = lgb.train(params = lgb_param, train_set = lgb_dtrain)\n",
    "# lgb_model_predict = np.argmax(lgb_model.predict(test_x), axis = 0)\n",
    "\n",
    "# print(\"Accuracy: %.2f\" % (accuracy_score(test_y, lgb_model_predict) * 100), \"%\") # 정확도 % 계산\n",
    "# print(\"Time: %.2f\" % (time.time() - start), \"seconds\") # 코드 실행 시간 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightgbm.basic.Booster at 0x1fec5380a90>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "180719.68562552982"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from math import sqrt\n",
    "\n",
    "sqrt(mean_squared_error(lgb_model.predict(test_x),test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble의 Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9595\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000566 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1719\n",
      "[LightGBM] [Info] Number of data points in the train set: 15129, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 537922.040056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9559\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000530 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1706\n",
      "[LightGBM] [Info] Number of data points in the train set: 15129, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 531900.921872\n",
      "9567\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000515 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1715\n",
      "[LightGBM] [Info] Number of data points in the train set: 15129, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 537480.432481\n",
      "9570\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000482 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1710\n",
      "[LightGBM] [Info] Number of data points in the train set: 15129, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 539774.287461\n",
      "9523\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000437 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1707\n",
      "[LightGBM] [Info] Number of data points in the train set: 15129, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 537810.618679\n",
      "9611\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000702 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1709\n",
      "[LightGBM] [Info] Number of data points in the train set: 15129, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 540846.949038\n",
      "9552\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000465 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1707\n",
      "[LightGBM] [Info] Number of data points in the train set: 15129, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 543635.240003\n",
      "9524\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000422 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1710\n",
      "[LightGBM] [Info] Number of data points in the train set: 15129, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 540766.196180\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "9524\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000433 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1712\n",
      "[LightGBM] [Info] Number of data points in the train set: 15129, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 538574.981162\n",
      "9504\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000465 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1712\n",
      "[LightGBM] [Info] Number of data points in the train set: 15129, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 536691.898275\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "baggin_predict_result = [] # 빈 리스트 형성\n",
    "for _ in range(10):\n",
    "    data_index = [data_index for data_index in range(train_x.shape[0])] # 학습데이터의 인덱스를 리스트로 변환\n",
    "    random_data_index = np.random.choice(data_index, train_x.shape[0]) \n",
    "    print(len(set(random_data_index)))\n",
    "    lgb_dtrain = lgb.Dataset(data = train_x.iloc[random_data_index,], label = train_y.iloc[random_data_index,])\n",
    "    lgb_param = {'max_depth' : 14, # 트리 깊이\n",
    "                'learning_rate' : 0.01, # Step size\n",
    "                'n_estimators' : 500, # 트리 생성 개수\n",
    "                'objective' : 'regression' # 목적 : 회귀분석 (?)\n",
    "                }\n",
    "    lgb_model = lgb.train(params = lgb_param, train_set = lgb_dtrain)\n",
    "    predict1 = lgb_model.predict(test_x)\n",
    "    baggin_predict_result.append(predict1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([1249185.57878622,  643352.19925481,  380703.77508608, ...,\n",
       "         291425.19430134,  730695.03675299,  995295.1343749 ]),\n",
       " array([1256807.18397116,  593413.34985371,  378487.71846895, ...,\n",
       "         281064.16398685,  736295.16736705,  972742.26328592]),\n",
       " array([1206989.5349773 ,  618486.74293827,  394276.43039988, ...,\n",
       "         295869.6900848 ,  741020.21924202, 1008184.14668011]),\n",
       " array([1137394.44055702,  615642.45328396,  401472.8251325 , ...,\n",
       "         281271.10073069,  742685.56752922,  985060.22036848]),\n",
       " array([1216020.50480135,  635812.2423234 ,  393652.95602299, ...,\n",
       "         275120.4610991 ,  706664.01033949,  931682.04318727]),\n",
       " array([1135113.88004514,  603760.04051463,  386518.36641   , ...,\n",
       "         299464.95012091,  713511.46939597,  979794.94946019]),\n",
       " array([1256296.0612623 ,  628941.49584051,  378427.87066729, ...,\n",
       "         286689.93440324,  710503.87195076, 1028372.88265254]),\n",
       " array([1293186.37932458,  632778.76950349,  373369.18149231, ...,\n",
       "         290914.42716145,  759860.27690134,  980305.90150062]),\n",
       " array([1234561.8942155 ,  619967.08869478,  401717.88941757, ...,\n",
       "         285608.92899131,  697196.85331737, 1046524.07464555]),\n",
       " array([1185354.01754277,  601469.59015749,  398000.21004974, ...,\n",
       "         323932.97540728,  761756.11684758,  986820.16826156])]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baggin_predict_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bagging 을 바탕으로 예측한 결과값에 대한 평균을 계싼\n",
    "baggin_predict = [] # 빈 list 형성\n",
    "for lst2_index in range(test_x.shape[0]): # test data의 개수만큼 반복\n",
    "    temp_predict = [] # 임시로 빈 리스트 형성\n",
    "    for lst_index in range(len(baggin_predict_result)): # Bagging 결과 리스트 반복\n",
    "        temp_predict.append(baggin_predict_result[lst_index][lst2_index]) # 각 Bagging 결과 예측한 값 중 같은 인덱스를 리스트에 저장\n",
    "    baggin_predict.append(np.mean(temp_predict)) # 해당 인덱스의 30개의 결과값에 대한 평균을 최종 리스트에 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE : 177526.62235590428\n"
     ]
    }
   ],
   "source": [
    "# 예측한 결과값들의 평균을 계산하여 실제 테스트 데이트의 타겟변수와 비교하여 성능 평가\n",
    "\n",
    "print('RMSE : {}'.format(sqrt(mean_squared_error(baggin_predict, test_y)))) # RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1217090.9475483347,\n",
       " 619362.3972365044,\n",
       " 388662.72231473273,\n",
       " 430429.7902139987,\n",
       " 460092.8540241138,\n",
       " 698944.5809055403,\n",
       " 1028101.0965050369,\n",
       " 659899.6987785941,\n",
       " 451248.56729572604,\n",
       " 500615.82193357975,\n",
       " 414338.4521542303,\n",
       " 336292.6748252989,\n",
       " 425867.2687308929,\n",
       " 442095.20852764975,\n",
       " 280039.24516915093,\n",
       " 577654.8307805189,\n",
       " 420390.06885322894,\n",
       " 430034.90359400195,\n",
       " 719683.2833766793,\n",
       " 452954.3283386092,\n",
       " 359127.47777827666,\n",
       " 474938.4101559903,\n",
       " 1064780.6149914484,\n",
       " 251657.8730761384,\n",
       " 662012.0045439231,\n",
       " 321520.2618119733,\n",
       " 762216.1591135275,\n",
       " 400803.61873696,\n",
       " 982248.9107709052,\n",
       " 973453.8583206963,\n",
       " 453597.9383819311,\n",
       " 632678.1993060864,\n",
       " 394091.88714393904,\n",
       " 399201.44154121185,\n",
       " 439248.6925081988,\n",
       " 439384.34064877266,\n",
       " 277425.29856596125,\n",
       " 505850.82595093467,\n",
       " 448287.1834931977,\n",
       " 335667.5233108675,\n",
       " 705384.8202239738,\n",
       " 367963.2522382465,\n",
       " 300859.471710377,\n",
       " 626657.5466628904,\n",
       " 405005.1901360684,\n",
       " 774672.8604523751,\n",
       " 244046.11199848875,\n",
       " 531033.473065442,\n",
       " 433395.28093456326,\n",
       " 1483509.1621474144,\n",
       " 792611.5953482098,\n",
       " 531111.6430192238,\n",
       " 569726.1237991306,\n",
       " 438503.55715882947,\n",
       " 518441.57775585755,\n",
       " 494882.50505855883,\n",
       " 446313.8971019268,\n",
       " 628720.2034244655,\n",
       " 397854.45516670536,\n",
       " 528524.09532468,\n",
       " 289622.8198887635,\n",
       " 1019466.5186183068,\n",
       " 667303.6809986619,\n",
       " 423444.6765566524,\n",
       " 712133.2064127467,\n",
       " 419494.3616321129,\n",
       " 1393960.9476448086,\n",
       " 422659.1996338501,\n",
       " 474543.2980018699,\n",
       " 399261.0954380519,\n",
       " 593927.647161996,\n",
       " 430602.8807768713,\n",
       " 305064.892410394,\n",
       " 984431.5604899448,\n",
       " 328649.2802906475,\n",
       " 480214.5695681258,\n",
       " 533779.2867698537,\n",
       " 498236.68560886773,\n",
       " 744696.8755439676,\n",
       " 382231.0140942396,\n",
       " 440713.0432254174,\n",
       " 470343.98218235176,\n",
       " 473735.73710569757,\n",
       " 287475.0872944428,\n",
       " 759809.3301908434,\n",
       " 579555.9492138107,\n",
       " 861792.9753729379,\n",
       " 495771.18035730923,\n",
       " 640085.2269034712,\n",
       " 839820.7019189993,\n",
       " 212510.8124063667,\n",
       " 630491.4097078353,\n",
       " 251357.85573239243,\n",
       " 753589.4996089187,\n",
       " 517650.9138814267,\n",
       " 518863.7981759876,\n",
       " 448083.11761688645,\n",
       " 650350.848902448,\n",
       " 262826.95559718326,\n",
       " 611388.1764835941,\n",
       " 637634.4658078849,\n",
       " 480849.70358748204,\n",
       " 337823.1837931753,\n",
       " 481336.89588081336,\n",
       " 586531.8932176991,\n",
       " 319060.07117736404,\n",
       " 335956.25128274027,\n",
       " 299808.76542005216,\n",
       " 616020.2852308315,\n",
       " 431149.4542841669,\n",
       " 329025.20327232115,\n",
       " 765110.8530356032,\n",
       " 253438.20318894327,\n",
       " 1231777.0844536936,\n",
       " 433452.54445702024,\n",
       " 272592.65409865533,\n",
       " 556726.7336436536,\n",
       " 373968.3599859151,\n",
       " 543781.6918689298,\n",
       " 339916.3163030398,\n",
       " 774108.3475042259,\n",
       " 380443.93529223074,\n",
       " 306495.91625136975,\n",
       " 322708.7225115265,\n",
       " 487681.11280817195,\n",
       " 471479.74270379695,\n",
       " 721496.981045192,\n",
       " 864360.8448067885,\n",
       " 1150327.222401283,\n",
       " 347925.729042705,\n",
       " 455424.43052087026,\n",
       " 758493.3628437773,\n",
       " 459179.3122937223,\n",
       " 901809.2095237036,\n",
       " 411929.6008889031,\n",
       " 878149.9362525365,\n",
       " 437876.1414404994,\n",
       " 337624.6989996667,\n",
       " 1224959.0105498896,\n",
       " 493844.9643868776,\n",
       " 652695.8722645725,\n",
       " 295944.7559482931,\n",
       " 2402793.2739555864,\n",
       " 609110.7143574584,\n",
       " 411513.54114815744,\n",
       " 520622.9584354737,\n",
       " 323106.8207249509,\n",
       " 270813.0065032864,\n",
       " 291327.0117422313,\n",
       " 414371.04408123484,\n",
       " 395622.4616537351,\n",
       " 312640.6428231957,\n",
       " 577025.7232062848,\n",
       " 579476.7504721408,\n",
       " 416844.940149472,\n",
       " 320007.33686802106,\n",
       " 373146.19522444357,\n",
       " 301353.27838416095,\n",
       " 357511.3039275688,\n",
       " 584706.3268202068,\n",
       " 515151.0722307899,\n",
       " 365996.8074791635,\n",
       " 388600.91720757453,\n",
       " 271845.04616000305,\n",
       " 487042.9528460539,\n",
       " 318861.4966164419,\n",
       " 417659.7410883688,\n",
       " 612309.9504951533,\n",
       " 290120.986340569,\n",
       " 491288.0362869421,\n",
       " 403677.0473234906,\n",
       " 641381.2285857338,\n",
       " 385538.9055532821,\n",
       " 334384.07869744365,\n",
       " 459067.5548971624,\n",
       " 294443.96137921413,\n",
       " 310037.99455382454,\n",
       " 303056.46366892516,\n",
       " 704439.0824253705,\n",
       " 421758.96615038987,\n",
       " 650705.3120914372,\n",
       " 421060.5790684443,\n",
       " 352749.60786880006,\n",
       " 338523.63819121907,\n",
       " 266588.5705075481,\n",
       " 680469.161196091,\n",
       " 381757.99173924513,\n",
       " 426460.6134671457,\n",
       " 241980.21133846726,\n",
       " 1080236.4910366468,\n",
       " 442179.7498994003,\n",
       " 314825.56403032946,\n",
       " 549150.3371596562,\n",
       " 453779.74433499866,\n",
       " 275362.08946841897,\n",
       " 305941.1342883491,\n",
       " 971317.0505490452,\n",
       " 484570.13770716114,\n",
       " 525142.168841231,\n",
       " 889353.4587060877,\n",
       " 498023.4942351788,\n",
       " 1018856.6800804449,\n",
       " 499723.30140273756,\n",
       " 553310.8104206766,\n",
       " 392016.8560927353,\n",
       " 774018.2895829041,\n",
       " 466995.3271280313,\n",
       " 349219.2580826427,\n",
       " 370426.0254884681,\n",
       " 795071.6724512248,\n",
       " 1078731.8000753894,\n",
       " 492870.9036503125,\n",
       " 557347.571804336,\n",
       " 391190.0546894671,\n",
       " 624338.77701268,\n",
       " 319075.97952468164,\n",
       " 786561.234189289,\n",
       " 243152.58023449575,\n",
       " 297737.9614315202,\n",
       " 467436.6516541251,\n",
       " 424697.53648781765,\n",
       " 472746.5709839904,\n",
       " 577649.2981516715,\n",
       " 415156.6507245436,\n",
       " 885378.9631620124,\n",
       " 733313.5815836585,\n",
       " 252364.00839670602,\n",
       " 274156.749940986,\n",
       " 415089.6046876939,\n",
       " 683854.9873726775,\n",
       " 673289.7580481118,\n",
       " 474435.2769779943,\n",
       " 311529.3957206114,\n",
       " 896342.8677175762,\n",
       " 749262.2879581059,\n",
       " 643395.3533768349,\n",
       " 492686.5979474316,\n",
       " 310031.65588305495,\n",
       " 376953.74879501347,\n",
       " 456991.61886243365,\n",
       " 228643.2582533847,\n",
       " 1670943.333699943,\n",
       " 405692.8027228996,\n",
       " 542427.6934790217,\n",
       " 916408.7749670629,\n",
       " 488093.62275094073,\n",
       " 426297.4348416209,\n",
       " 744716.1795676134,\n",
       " 780115.5398601094,\n",
       " 297303.5400273528,\n",
       " 384656.62713480287,\n",
       " 431604.3116834797,\n",
       " 417924.84143095324,\n",
       " 708376.6025042662,\n",
       " 675760.0662767935,\n",
       " 428616.8858819185,\n",
       " 354784.0438977709,\n",
       " 548053.7446674976,\n",
       " 509713.8450503036,\n",
       " 491594.976163563,\n",
       " 432504.5637674889,\n",
       " 890267.4623039502,\n",
       " 885399.0985684923,\n",
       " 435043.61469021643,\n",
       " 554579.9476015432,\n",
       " 587515.4388126916,\n",
       " 295076.0919884901,\n",
       " 571932.1075877029,\n",
       " 536081.5076798091,\n",
       " 675762.3655105494,\n",
       " 326354.9657357754,\n",
       " 582455.7838268798,\n",
       " 685373.1928658595,\n",
       " 317538.7059531536,\n",
       " 1195365.0816149283,\n",
       " 481801.18544071587,\n",
       " 562951.2529983198,\n",
       " 574433.34026995,\n",
       " 317911.5314140425,\n",
       " 296930.8811266716,\n",
       " 352489.1192516618,\n",
       " 452456.2978997574,\n",
       " 495281.7540438152,\n",
       " 539534.4199067217,\n",
       " 1525522.8865811243,\n",
       " 337544.5280103365,\n",
       " 467213.0397752732,\n",
       " 264070.7088169744,\n",
       " 538684.4071393844,\n",
       " 584404.5472255336,\n",
       " 320587.49134833063,\n",
       " 666436.1521921468,\n",
       " 571100.9743679573,\n",
       " 974756.6937549788,\n",
       " 528304.5857298877,\n",
       " 492017.28119452146,\n",
       " 839100.0731623636,\n",
       " 606329.4000381093,\n",
       " 422219.3839284945,\n",
       " 323244.66898340755,\n",
       " 476443.39071839454,\n",
       " 365727.36010984937,\n",
       " 345018.7742445851,\n",
       " 305838.856969756,\n",
       " 377999.3357275116,\n",
       " 571716.4896414166,\n",
       " 407615.1303241083,\n",
       " 938168.2955684128,\n",
       " 545162.4823830813,\n",
       " 1018498.7144419921,\n",
       " 441918.0149297657,\n",
       " 468376.49058047717,\n",
       " 316801.50222004286,\n",
       " 1607972.5538116733,\n",
       " 659795.1972828282,\n",
       " 416787.7554054739,\n",
       " 360755.7347358106,\n",
       " 485441.9032942668,\n",
       " 464670.05775223905,\n",
       " 456251.006584868,\n",
       " 843310.325509904,\n",
       " 294601.4719307007,\n",
       " 1790473.0321377325,\n",
       " 418903.18002093415,\n",
       " 556874.5249933632,\n",
       " 638260.6935245192,\n",
       " 440777.4926702299,\n",
       " 449720.32943729765,\n",
       " 910451.8622442177,\n",
       " 3025579.226151188,\n",
       " 823980.7582150083,\n",
       " 440777.4926702299,\n",
       " 437228.0092347718,\n",
       " 482092.4457734621,\n",
       " 567471.0612634316,\n",
       " 598853.5920011228,\n",
       " 326707.06701545627,\n",
       " 441354.1451631532,\n",
       " 628050.1197456003,\n",
       " 542189.0069418198,\n",
       " 959996.8645527067,\n",
       " 499250.64570037153,\n",
       " 449156.99089563347,\n",
       " 785110.5157757209,\n",
       " 437865.09844839916,\n",
       " 302317.38548380963,\n",
       " 469898.94202035666,\n",
       " 356201.42774127563,\n",
       " 407583.0346740231,\n",
       " 936186.548303114,\n",
       " 809606.8358147817,\n",
       " 551990.342664745,\n",
       " 293456.3184089063,\n",
       " 424091.22270995175,\n",
       " 428206.25005801197,\n",
       " 270669.0205148818,\n",
       " 764225.6466583794,\n",
       " 381119.56388985034,\n",
       " 324896.8670312146,\n",
       " 1278837.3355519506,\n",
       " 324891.312768268,\n",
       " 788855.6734902092,\n",
       " 1023990.5344777113,\n",
       " 285215.7484421787,\n",
       " 336396.9280931366,\n",
       " 273659.6262357879,\n",
       " 342685.890726423,\n",
       " 490252.22567026934,\n",
       " 638406.5318222784,\n",
       " 645955.5337569786,\n",
       " 436731.1477676835,\n",
       " 379436.5747833667,\n",
       " 265960.74855929683,\n",
       " 346165.33498629933,\n",
       " 238900.14584392047,\n",
       " 382823.08642870944,\n",
       " 270037.84719212796,\n",
       " 434361.52349948464,\n",
       " 400804.9835129383,\n",
       " 512141.05784957315,\n",
       " 381605.7671649818,\n",
       " 353487.5947710543,\n",
       " 323168.22520961455,\n",
       " 677091.3606785018,\n",
       " 576280.0515150249,\n",
       " 911198.0848385872,\n",
       " 275430.91086081124,\n",
       " 324633.2223164898,\n",
       " 541717.9527814853,\n",
       " 430971.51597843354,\n",
       " 379069.7443681086,\n",
       " 555594.6570352397,\n",
       " 256209.56492642028,\n",
       " 1361472.5239276383,\n",
       " 509787.9044167444,\n",
       " 845056.8373621848,\n",
       " 877883.1726876255,\n",
       " 727123.4005246408,\n",
       " 871153.5265566567,\n",
       " 577098.3037718647,\n",
       " 403163.30971317727,\n",
       " 660507.5772964869,\n",
       " 370168.9010522204,\n",
       " 621698.0461297598,\n",
       " 420286.3571334925,\n",
       " 442825.54711121134,\n",
       " 363481.42362673976,\n",
       " 1421284.9400387877,\n",
       " 325326.63607760024,\n",
       " 388116.7827304603,\n",
       " 294189.54211299605,\n",
       " 219413.2255442657,\n",
       " 497600.34138051496,\n",
       " 802570.1504638463,\n",
       " 432913.7224943228,\n",
       " 495766.01513644494,\n",
       " 582474.6486812171,\n",
       " 395378.640060084,\n",
       " 501785.10187957744,\n",
       " 913665.5152918401,\n",
       " 366645.4994326512,\n",
       " 563851.2277210921,\n",
       " 437359.4151975695,\n",
       " 440769.0977968988,\n",
       " 451389.9964891459,\n",
       " 321120.8311976261,\n",
       " 454134.40198191034,\n",
       " 425745.6907613327,\n",
       " 452379.06250914314,\n",
       " 411490.52073945815,\n",
       " 575797.537931174,\n",
       " 442426.31502681086,\n",
       " 402382.4516144978,\n",
       " 286681.4823081031,\n",
       " 791220.5486132767,\n",
       " 320796.53193414357,\n",
       " 369535.8822879553,\n",
       " 617362.3130722409,\n",
       " 472582.22872038715,\n",
       " 487499.3840995525,\n",
       " 1490508.3867215754,\n",
       " 316508.54633133806,\n",
       " 455974.1867887724,\n",
       " 562200.0981509319,\n",
       " 354186.73791932565,\n",
       " 411718.3327080644,\n",
       " 424577.1292780869,\n",
       " 406547.51718381967,\n",
       " 317843.13222649763,\n",
       " 379776.22147890046,\n",
       " 605642.8398510425,\n",
       " 466796.98245555937,\n",
       " 467119.42976820265,\n",
       " 355460.1514678028,\n",
       " 528742.6597283083,\n",
       " 376485.6517845801,\n",
       " 508774.0217225497,\n",
       " 485388.49578567606,\n",
       " 323464.5777427951,\n",
       " 310294.41964701406,\n",
       " 455225.3453119059,\n",
       " 241575.1484930397,\n",
       " 499576.78606661677,\n",
       " 266133.5537758527,\n",
       " 364405.76906992245,\n",
       " 256033.58102050232,\n",
       " 573902.8346894687,\n",
       " 698375.190611244,\n",
       " 499149.24520231877,\n",
       " 304265.66791021114,\n",
       " 344583.591700122,\n",
       " 388919.8482950198,\n",
       " 1127662.5195289003,\n",
       " 733299.1984064067,\n",
       " 294382.38261479244,\n",
       " 353387.2445655437,\n",
       " 433458.5796834127,\n",
       " 834166.4952472623,\n",
       " 310249.31653148815,\n",
       " 361080.31376887124,\n",
       " 582277.4283043961,\n",
       " 317465.9965000514,\n",
       " 431645.11989214673,\n",
       " 435039.11956965877,\n",
       " 691145.0183585465,\n",
       " 501500.28352064884,\n",
       " 361009.7202039316,\n",
       " 372455.86354703794,\n",
       " 660343.6536371261,\n",
       " 250285.39677294483,\n",
       " 372726.5467319851,\n",
       " 895335.6520350097,\n",
       " 455669.5778273892,\n",
       " 263852.26037918945,\n",
       " 1944354.9898707427,\n",
       " 456891.11803194566,\n",
       " 728346.3783126442,\n",
       " 368633.8664443772,\n",
       " 433885.81714544183,\n",
       " 348244.4223438248,\n",
       " 803623.2156789976,\n",
       " 518409.71995184256,\n",
       " 558795.8314661536,\n",
       " 247453.37964889352,\n",
       " 389627.8835419628,\n",
       " 264003.21348540054,\n",
       " 294274.5822441677,\n",
       " 444450.02674434875,\n",
       " 365898.98087283876,\n",
       " 340885.14816886524,\n",
       " 1058280.6859504655,\n",
       " 451580.4729684581,\n",
       " 551291.5233779582,\n",
       " 461455.96196858754,\n",
       " 501907.57283333025,\n",
       " 626289.7769036416,\n",
       " 428855.7276175592,\n",
       " 917844.8312986565,\n",
       " 479738.68099723116,\n",
       " 549396.7205419891,\n",
       " 391805.13086900586,\n",
       " 526890.2003497796,\n",
       " 409651.08783161436,\n",
       " 405251.85881825705,\n",
       " 734578.5406529715,\n",
       " 392214.0715278231,\n",
       " 460287.0758318792,\n",
       " 595659.9049620972,\n",
       " 314978.20361252443,\n",
       " 1663680.3441337685,\n",
       " 281470.2206481251,\n",
       " 281573.4471019624,\n",
       " 667373.8718317002,\n",
       " 471845.37717090436,\n",
       " 884536.7545472102,\n",
       " 348442.51637823833,\n",
       " 345044.24023707386,\n",
       " 563257.888018119,\n",
       " 385081.9133952627,\n",
       " 646766.4192096938,\n",
       " 294355.8365318165,\n",
       " 558021.0633056846,\n",
       " 709932.680950234,\n",
       " 282849.59543793334,\n",
       " 335513.4980969918,\n",
       " 313611.1425785009,\n",
       " 994255.0707276228,\n",
       " 284945.3356277635,\n",
       " 354113.4808020964,\n",
       " 546045.7593904458,\n",
       " 1156891.377517947,\n",
       " 957594.2042734638,\n",
       " 481342.98673615104,\n",
       " 775810.8278721017,\n",
       " 327122.9155816325,\n",
       " 327332.32675438933,\n",
       " 743210.7992158311,\n",
       " 481668.7349096071,\n",
       " 446875.4035641483,\n",
       " 481285.42295689025,\n",
       " 427192.51767173706,\n",
       " 588880.5842345764,\n",
       " 437608.4394818611,\n",
       " 775514.9943195947,\n",
       " 443555.5745670963,\n",
       " 1552971.8279404584,\n",
       " 346526.6613894248,\n",
       " 458579.3068932021,\n",
       " 464056.3554094805,\n",
       " 505686.7691304283,\n",
       " 513832.1956335382,\n",
       " 307561.01128061366,\n",
       " 330018.65669063,\n",
       " 448579.58515647426,\n",
       " 1385585.0598376284,\n",
       " 418495.78352781705,\n",
       " 1059394.358632184,\n",
       " 580642.7972138834,\n",
       " 524088.8378575259,\n",
       " 351205.2884436443,\n",
       " 429657.46667128586,\n",
       " 438829.1711771598,\n",
       " 453391.1403122645,\n",
       " 461580.0717716051,\n",
       " 303499.9441675286,\n",
       " 253493.05032113258,\n",
       " 432224.0544269789,\n",
       " 458649.4299426076,\n",
       " 313193.48443519283,\n",
       " 580484.8282905815,\n",
       " 888604.5343669845,\n",
       " 514773.0326351448,\n",
       " 341380.5694234025,\n",
       " 587266.4706975901,\n",
       " 293638.1127044219,\n",
       " 874468.6665338343,\n",
       " 367847.2813777732,\n",
       " 336791.3564372711,\n",
       " 663591.2548635509,\n",
       " 244550.25690940712,\n",
       " 2081892.5003733742,\n",
       " 406834.91825463815,\n",
       " 443050.395016048,\n",
       " 461819.54547184176,\n",
       " 288313.3068455091,\n",
       " 392655.68392061663,\n",
       " 339437.51398539887,\n",
       " 349927.5841502232,\n",
       " 449107.9488396713,\n",
       " 661359.0981207961,\n",
       " 386107.0582046785,\n",
       " 500179.9096072656,\n",
       " 375087.61224125867,\n",
       " 310397.44006410835,\n",
       " 444046.8157923805,\n",
       " 381472.84331678576,\n",
       " 348927.0078728567,\n",
       " 366117.9620174764,\n",
       " 812666.5459318935,\n",
       " 676913.9754078869,\n",
       " 470247.1135252472,\n",
       " 960034.1379489994,\n",
       " 522559.72700797254,\n",
       " 340092.70176175254,\n",
       " 507692.33139163547,\n",
       " 511891.7655219746,\n",
       " 328759.3706605348,\n",
       " 308970.0983402269,\n",
       " 481054.9978882226,\n",
       " 348737.56894063065,\n",
       " 541154.9608077031,\n",
       " 281338.6723747382,\n",
       " 340422.8097146081,\n",
       " 893855.7990471512,\n",
       " 309857.94978247385,\n",
       " 463993.94882445096,\n",
       " 589229.5653450938,\n",
       " 482611.1256295593,\n",
       " 277855.86350341665,\n",
       " 366472.9809873841,\n",
       " 575907.7828233087,\n",
       " 566161.0961953979,\n",
       " 545992.7021843253,\n",
       " 252682.39661308852,\n",
       " 269244.99417011486,\n",
       " 1159664.729826322,\n",
       " 996810.4980130431,\n",
       " 669003.6940754869,\n",
       " 475881.2126464123,\n",
       " 290389.49934515584,\n",
       " 565285.1891497611,\n",
       " 400011.792127532,\n",
       " 420752.9832609367,\n",
       " 357554.8586489076,\n",
       " 300341.89168047474,\n",
       " 453818.10595470946,\n",
       " 336009.15758286556,\n",
       " 299087.4692473408,\n",
       " 333713.7893288949,\n",
       " 645678.9339404267,\n",
       " 270883.82142450666,\n",
       " 738254.7296321455,\n",
       " 726424.2024151126,\n",
       " 1448255.9226925843,\n",
       " 660080.5177536502,\n",
       " 608489.0607141744,\n",
       " 363028.09853628336,\n",
       " 934337.4064357117,\n",
       " 480279.6029298045,\n",
       " 378423.3714246815,\n",
       " 450564.0766373558,\n",
       " 562216.1624216881,\n",
       " 654098.1924303728,\n",
       " 787010.7292364833,\n",
       " 448282.1409518928,\n",
       " 869319.0214228702,\n",
       " 244076.28198946634,\n",
       " 553188.02230104,\n",
       " 627139.8864956793,\n",
       " 620276.5938274815,\n",
       " 441602.33488357783,\n",
       " 685735.7566558184,\n",
       " 780773.1845061984,\n",
       " 401661.7361506173,\n",
       " 511772.37710815045,\n",
       " 488949.9142342339,\n",
       " 454889.0721099144,\n",
       " 640552.7348647224,\n",
       " 412015.9583617901,\n",
       " 428075.42392761103,\n",
       " 385198.27027685347,\n",
       " 705818.9964097646,\n",
       " 396297.49452009157,\n",
       " 533349.5114718596,\n",
       " 715297.4905147507,\n",
       " 248277.61687297683,\n",
       " 463065.8399188769,\n",
       " 347315.4328189975,\n",
       " 565582.323170085,\n",
       " 811657.0823061138,\n",
       " 390183.9463439196,\n",
       " 250507.04309634687,\n",
       " 394908.9071587391,\n",
       " 531082.1312913975,\n",
       " 318147.9030428742,\n",
       " 428055.3319439789,\n",
       " 397037.0190062451,\n",
       " 473782.0986330338,\n",
       " 299433.33037817496,\n",
       " 564479.4783248731,\n",
       " 598272.6022076762,\n",
       " 236788.61696407516,\n",
       " 612389.6628589913,\n",
       " 795497.1245647284,\n",
       " 418713.44017846975,\n",
       " 421672.84505387896,\n",
       " 291764.21059471555,\n",
       " 872262.9067571542,\n",
       " 2135167.955123591,\n",
       " 293592.9666437785,\n",
       " 261794.69478529278,\n",
       " 643219.0761490982,\n",
       " 309193.00148202886,\n",
       " 312098.99512160604,\n",
       " 349809.32597266586,\n",
       " 664124.3349597002,\n",
       " 476306.42612393724,\n",
       " 389229.91126170586,\n",
       " 596775.5185424641,\n",
       " 997140.7186114837,\n",
       " 419936.07418050396,\n",
       " 398311.61199855985,\n",
       " 258667.9684599428,\n",
       " 332359.32649926085,\n",
       " 566078.1379190112,\n",
       " 679792.6110145435,\n",
       " 303042.0129519147,\n",
       " 353914.1782423512,\n",
       " 321294.7185903226,\n",
       " 419874.5113141956,\n",
       " 291537.11347941187,\n",
       " 482143.5827335144,\n",
       " 356049.52649712487,\n",
       " 246975.36345786345,\n",
       " 314448.4334884911,\n",
       " 350832.7286424841,\n",
       " 783891.809405818,\n",
       " 356970.16836389626,\n",
       " 778820.721844726,\n",
       " 439215.0519892187,\n",
       " 541453.2079595968,\n",
       " 597391.2959369324,\n",
       " 857160.4732272144,\n",
       " 303642.6792341905,\n",
       " 438349.2471458566,\n",
       " 257882.8464944026,\n",
       " 354938.1522969947,\n",
       " 362525.8375674233,\n",
       " 528000.6685037866,\n",
       " 601845.6517278447,\n",
       " 1138202.633749018,\n",
       " 445017.6509311694,\n",
       " 681527.3708412921,\n",
       " 739380.8730265561,\n",
       " 1336962.1993689253,\n",
       " 535507.5835501475,\n",
       " 479516.4181843166,\n",
       " 357407.33730304136,\n",
       " 854417.2094437906,\n",
       " 280956.119323059,\n",
       " 475815.9688284638,\n",
       " 356718.8542155124,\n",
       " 323485.01783468074,\n",
       " 328791.2120083406,\n",
       " 359194.0677320269,\n",
       " 495818.67685704154,\n",
       " 904354.3108453024,\n",
       " 398337.22443909955,\n",
       " 476819.22998040775,\n",
       " 633271.7533889601,\n",
       " 461618.8917982581,\n",
       " 441648.96426098625,\n",
       " 412834.86292652,\n",
       " 577071.305872968,\n",
       " 330940.7948106034,\n",
       " 296677.72674842493,\n",
       " 494663.3551296339,\n",
       " 307474.3455034527,\n",
       " 515217.440115476,\n",
       " 507932.6352572314,\n",
       " 334122.39709863643,\n",
       " 442198.73686751054,\n",
       " 376432.78869747306,\n",
       " 817703.6042091248,\n",
       " 261833.6539828959,\n",
       " 323808.9061670095,\n",
       " 423207.2966316164,\n",
       " 707579.9602680425,\n",
       " 374775.78967344906,\n",
       " 699047.3031404372,\n",
       " 391048.91221591784,\n",
       " 318882.43979930045,\n",
       " 277983.38394237123,\n",
       " 436322.31106706895,\n",
       " 425249.92006427125,\n",
       " 1022132.9270090725,\n",
       " 626965.089312755,\n",
       " 403591.2475734862,\n",
       " 315332.84128119436,\n",
       " 421569.041132856,\n",
       " 311425.93837868434,\n",
       " 480770.979840933,\n",
       " 687438.2531025063,\n",
       " 250136.58193828174,\n",
       " 473743.5054470844,\n",
       " 964887.0490334742,\n",
       " 435034.1147282183,\n",
       " 439426.88346903195,\n",
       " 676265.4414545791,\n",
       " 1113369.365002574,\n",
       " 587363.2784811604,\n",
       " 555327.9025851,\n",
       " 709239.3317283933,\n",
       " 594696.9949699105,\n",
       " 315277.5051461995,\n",
       " 783523.0203595314,\n",
       " 423066.6325625214,\n",
       " 1436027.1350690627,\n",
       " 504044.8047352831,\n",
       " 753533.6245324685,\n",
       " 459616.71296770324,\n",
       " 439898.06645345315,\n",
       " 585680.7852843512,\n",
       " 2355440.5776049285,\n",
       " 603336.5596139507,\n",
       " 351089.47267162136,\n",
       " 449516.5340221828,\n",
       " 638604.9746557014,\n",
       " 427677.33215464593,\n",
       " 461485.64334630396,\n",
       " 619741.4700207959,\n",
       " 522133.39024801645,\n",
       " 316300.6944233895,\n",
       " 404516.8099924406,\n",
       " 983041.7191752668,\n",
       " 264625.7442468518,\n",
       " 599280.2561376474,\n",
       " 373239.58286667813,\n",
       " 1142140.3696349047,\n",
       " 425648.1990943105,\n",
       " 313735.625597131,\n",
       " 321494.0256090864,\n",
       " 562591.4142632048,\n",
       " 398673.4085699489,\n",
       " 333850.6953469748,\n",
       " 368224.8818401899,\n",
       " 698694.5620691782,\n",
       " 280972.31260824593,\n",
       " 499380.6308004094,\n",
       " 354878.15014961985,\n",
       " 370458.6750482087,\n",
       " 1426215.9791739762,\n",
       " 644903.1111042129,\n",
       " 351387.48215442325,\n",
       " 491767.8969152874,\n",
       " 425185.46616901486,\n",
       " 274097.23782190355,\n",
       " 649176.4073052007,\n",
       " 593393.471695229,\n",
       " 584397.0500376107,\n",
       " 2944049.765933839,\n",
       " 428275.60913812474,\n",
       " 313760.58673029684,\n",
       " 630429.3226016402,\n",
       " 590959.6079283227,\n",
       " 378199.49714612484,\n",
       " 441862.2085817127,\n",
       " 295802.93954962224,\n",
       " 439565.27614136634,\n",
       " 698268.6658718222,\n",
       " 498444.3202640064,\n",
       " 397474.87729214906,\n",
       " 714183.9157150232,\n",
       " 449543.806860563,\n",
       " 519023.87355103437,\n",
       " 626905.4257076948,\n",
       " 405855.7402656897,\n",
       " 431510.2263479108,\n",
       " 261658.26423408845,\n",
       " 431114.18246673635,\n",
       " 340077.5958395698,\n",
       " 316697.3208165049,\n",
       " 313233.22295134485,\n",
       " 582030.5268045621,\n",
       " 575525.6061969654,\n",
       " 234748.13385104682,\n",
       " 416034.13245606015,\n",
       " 426557.7245060378,\n",
       " 1062508.8711710405,\n",
       " 657386.8397438409,\n",
       " 626090.4222054187,\n",
       " 2039327.8917104476,\n",
       " 472147.09250794165,\n",
       " 463466.51387080114,\n",
       " 313838.5385546474,\n",
       " 511627.69152779476,\n",
       " 310131.6810748326,\n",
       " 480420.70217720943,\n",
       " 662828.8579899863,\n",
       " 1184406.814713886,\n",
       " 477434.84234935243,\n",
       " 403331.2512023522,\n",
       " 356000.5720522608,\n",
       " 341477.3173372111,\n",
       " 261414.49145003277,\n",
       " 687841.7678262092,\n",
       " 880594.3308943216,\n",
       " 564226.9603068241,\n",
       " 1439495.468826956,\n",
       " 493506.4727566245,\n",
       " 465735.7688772412,\n",
       " 1489100.1372945278,\n",
       " 445566.7953082804,\n",
       " 397288.47946695297,\n",
       " 427546.87177852273,\n",
       " 539565.6383439938,\n",
       " 663310.5643882675,\n",
       " 875649.2223022289,\n",
       " 373696.74064538366,\n",
       " 386414.3572274072,\n",
       " 430954.1738887372,\n",
       " 465606.10801320104,\n",
       " 331922.5496353171,\n",
       " 453448.84296159045,\n",
       " 370258.9019767625,\n",
       " 452431.6160704925,\n",
       " 550909.744150015,\n",
       " 547005.5737467066,\n",
       " 535308.1688427576,\n",
       " 451470.8201236922,\n",
       " 505908.1223790144,\n",
       " 614101.088971256,\n",
       " 631024.1595880764,\n",
       " 619524.4909595678,\n",
       " 261428.30862600534,\n",
       " 334444.3631999,\n",
       " 610854.7814864691,\n",
       " 679947.9902536465,\n",
       " 393406.59328051296,\n",
       " 396015.0932136802,\n",
       " 484953.31236003386,\n",
       " 403630.2912037655,\n",
       " 615408.66435423,\n",
       " 398573.34759139025,\n",
       " 278316.2698751326,\n",
       " 861746.6631842966,\n",
       " 638536.725428378,\n",
       " 505332.7809311788,\n",
       " 426595.70622073754,\n",
       " 434581.6489836841,\n",
       " 453644.63237600477,\n",
       " 492651.75234008377,\n",
       " 248465.78213498514,\n",
       " 413398.4341286906,\n",
       " 459940.34162240615,\n",
       " 857065.9835461348,\n",
       " 453742.01976986526,\n",
       " 608661.190073725,\n",
       " 291480.70511412213,\n",
       " 547403.4174554467,\n",
       " 429955.7518488738,\n",
       " 251119.59008173397,\n",
       " 432829.45639984065,\n",
       " 272246.4075619514,\n",
       " 381078.78212286084,\n",
       " 269969.65183461463,\n",
       " 397426.41761281097,\n",
       " 503599.6737179312,\n",
       " 324183.6958084807,\n",
       " 987966.8124083508,\n",
       " 434271.2240085622,\n",
       " 582276.2333183995,\n",
       " 543196.3270963858,\n",
       " 234978.15319628725,\n",
       " 377818.3254449753,\n",
       " 314748.9830825887,\n",
       " 555416.1317256491,\n",
       " 566605.3824167027,\n",
       " 741682.3000207092,\n",
       " 2776329.329241031,\n",
       " 320680.5306622121,\n",
       " 601616.9814669335,\n",
       " 491727.99970291916,\n",
       " 338128.152408667,\n",
       " 456239.4251080076,\n",
       " 268209.82780032454,\n",
       " 265093.42403747165,\n",
       " 377722.2807647915,\n",
       " 505998.5989358506,\n",
       " 325146.31067594874,\n",
       " ...]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baggin_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
