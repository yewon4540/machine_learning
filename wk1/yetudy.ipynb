{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 데이터 로드\n",
    "- 파이썬 버전 체크\n",
    "```\n",
    "import sys\n",
    "assert sys.version_info >= (3. 7) # 3.7 버전 이상\n",
    "```\n",
    "- 사이킷런 버전 체크\n",
    "```\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"1.0.1 # 1.0.1 버전 이상\n",
    "```\n",
    "- 데이터 로드\n",
    "    - 데이터 구하기\n",
    "    - 데이터 다운로드\n",
    "        - pathlib # 경로를 객체로서 조작 처리 가능\n",
    "        - tarfile # 파일 압축풀기\n",
    "        - urllib.request # URL 열기 라이브러리\n",
    "        - pandas # pd 형식으로 열기\n",
    "    - 데이터 구조 파악\n",
    "        - df 구조\n",
    "            - head, info\n",
    "            - 범주형 : value_counts\n",
    "            - 수치형 : describe\n",
    "        - 시각화\n",
    "            - pyplot, seaborn\n",
    "        - 상관계수 확인\n",
    "            - corr\n",
    "                ``` \n",
    "                corr = df.corr()\n",
    "                corr['column name'].sort_values(ascending=T/F)\n",
    "                ```\n",
    "\n",
    "\n",
    "#### 2. 데이터 처리(전처리)\n",
    "- training 할 정보와 관련없는 columns 은 drop\n",
    "- 연관성 있는 데이터들 분류 작업\n",
    "    - pivot으로 두개의 column의 연관정보를 데이터프레임으로 만들 수 있음\n",
    "- 데이터셋이 미리 나눠져 있었다면 concat, merge 를 이용하여 합친 후 전처리 진행\n",
    "\n",
    "\n",
    "#### 3. 결측치 제거, 이상치 처리\n",
    "- isna로 결측치 확인\n",
    "    - fillna, mean 등 상황에 맞게 활용\n",
    "\n",
    "    \n",
    "#### 4. 범주형 변수생성 (get dummies)\n",
    "- One Hot Encoding\n",
    "    ```\n",
    "    one_hot = pd.get_dummies(housing['ocean_proximity'])\n",
    "    housing = pd.concat([housing, one_hot], axis= 1)\n",
    "    housing.drop(['ocean_proximity'], axis=1, inplace=True)\n",
    "    ```\n",
    "\n",
    "\n",
    "#### 5. 데이터 분리\n",
    "- training / test data set (X, y)\n",
    "    - y_train => label(y값)선택\n",
    "    - X_train => X값 선택\n",
    "    - y_test, X_test\n",
    "```\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "# 80퍼센트는 트레이닝, 20퍼센트까지 테스트 모델로 정한다. random_state -> 난수\n",
    "```\n",
    "\n",
    "\n",
    "#### 6. 연속형 변수 처리 scailling (내용추가 필요)\n",
    "- 스케일링 (스케일링 값은 변수에 넣어서 사용해야 함.)\n",
    "from sklearn.preprocessing import StandardScaler # StandardScaler : 평균과 표준편차로 나눠주는 것\n",
    "sc = StandardScaler()\n",
    "train = sc.fit_transform(X_train)\n",
    "test = sc.transform(X_test)\n",
    "\n",
    "\n",
    "#### 7. 모델 빌드 ex) randomforest, xgboost\n",
    "- 수치형 데이터\n",
    "    - \n",
    "- 범주형 데이터\n",
    "    - \n",
    "\n",
    "\n",
    "#### 8. 성능 측정 (정확도 측정)\n",
    "- RMSE\n",
    "    - 예측값과 타깃 사이의 오차 제곱의 평균값\n",
    "        - MSE에 ROOT를 씌운 값\n",
    "- R2\n",
    "    - 회귀 모델에서 예측의 적합도를 0~1 값으로 계산한 것\n",
    "        - 1에 가까울수록 완벽함(y_train의 평균으로 계산)\n",
    "- ex\n",
    "    - \n",
    "\n",
    "#### 9. 모델 저장\n",
    "- 저장 방법\n",
    "    - 성능 측정 값이 입력된 Dataframe 저장(선언)\n",
    "    - sub.to_csv('경로', index=T/F)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
